{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import momi\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Be sure to log output\n",
    "logging.basicConfig(level=logging.INFO, filename=\"log-AllAdmix-RandStarts-InitFit_Continued.log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# THIS IS THE SAME AS THE OTHER MODEL 1, BUT WITH RANDOM STARTING VALUES TO \n",
    "# SEE IF THERE ARE LOCAL OPTIMA THAT WE'RE GETTING TRAPPED \n",
    "full_model = momi.DemographicModel(\n",
    "    N_e=3500000, gen_time=1.5, muts_per_gen=3.5e-9)\n",
    "\n",
    "\n",
    "# First specify the parameters we will be using when adding to the model\n",
    "# Since we have no idea about divergence times yet, we're going to begin by \n",
    "# assuming constant population sizes because we want to avoid specification \n",
    "# of times for size changes, as these could be incompatible with divergence times\n",
    "# and will make the number of free parameters in the model explode\n",
    "\n",
    "# Pop sizes - ordered from past to present - will have plausible ranges specified from MSMC Ne estimates\n",
    "# Each species will have one population size during the time prior to the next split/species divergence\n",
    "# This is during the \"waiting time\" til specieation. Then, within each will have three unique population \n",
    "# sizes estimated. This is to limit computational complexity. Still a lot of free parameters!\n",
    "\n",
    "# random initial (origination) value for pop sizes, with a specified plausible range\n",
    "# These can be considered pop sizes immediately post-divergence\n",
    "full_model.add_size_param(\"n_mm\", lower = 50000, upper = 50000000)\n",
    "full_model.add_size_param(\"n_crm\", lower = 50000, upper = 50000000)\n",
    "full_model.add_size_param(\"n_mongo\", lower = 50, upper = 5000000)\n",
    "full_model.add_size_param(\"n_pungu\", lower = 50, upper = 5000000)\n",
    "full_model.add_size_param(\"n_dikume\", lower = 50, upper = 5000000)\n",
    "full_model.add_size_param(\"n_caroli\", lower = 50, upper = 5000000)\n",
    "\n",
    "# One pop size change that occurs following some time after divergence for all species\n",
    "full_model.add_size_param(\"n_mm_1\", lower = 100, upper = 50000000)\n",
    "full_model.add_size_param(\"n_crm_1\", lower = 100, upper = 50000000)\n",
    "full_model.add_size_param(\"n_mongo_1\", lower = 100, upper = 5000000)\n",
    "full_model.add_size_param(\"n_pungu_1\", lower = 100, upper = 5000000)\n",
    "full_model.add_size_param(\"n_dikume_1\", lower = 100, upper = 5000000)\n",
    "full_model.add_size_param(\"n_caroli_1\", lower = 100, upper = 5000000)\n",
    "\n",
    "# Another one for the 'longer' persisting branches\n",
    "# Again, caroli gets one here because of the 'waiting time' till speciation in Barombi mbo post colonization\n",
    "full_model.add_size_param(\"n_mm_2\", lower = 100, upper = 50000000)\n",
    "full_model.add_size_param(\"n_crm_2\", lower = 100, upper = 50000000)\n",
    "full_model.add_size_param(\"n_caroli_2\", lower = 100, upper = 5000000)\n",
    "full_model.add_size_param(\"n_mongo_2\", lower = 100, upper = 5000000)\n",
    "full_model.add_size_param(\"n_pungu_2\", lower = 100, upper = 5000000)\n",
    "full_model.add_size_param(\"n_dikume_2\", lower = 100, upper = 5000000)\n",
    "\n",
    "# And then one last one for the riverine pops, since we want to estimate a more recent pop size for them\n",
    "# in addition to the more ancient pop sizes. \n",
    "full_model.add_size_param(\"n_mm_3\", lower = 100, upper = 50000000)\n",
    "full_model.add_size_param(\"n_crm_3\", lower = 100, upper = 50000000)\n",
    "full_model.add_size_param(\"n_caroli_3\", lower = 100, upper = 5000000)\n",
    "full_model.add_size_param(\"n_mongo_3\", lower = 100, upper = 5000000)\n",
    "full_model.add_size_param(\"n_pungu_3\", lower = 100, upper = 5000000)\n",
    "\n",
    "# random initial value for divergence times, with plausible ranges\n",
    "# The lake formed 2 million years ago, so that will serve as upper bound \n",
    "# for the initial divergence of the BMbo clade, as well as for everything \n",
    "# within the lake. We will conservatively set 1000 years ago as the lower bound\n",
    "full_model.add_time_param(\"t_mm_crm\", lower = 100000, upper = 2000000)\n",
    "# Bmbo_anc is time at which the lake was colonized/the group diverged from riverine, \n",
    "# whereas mongo_myaka is the time at which mongo/myaka split from this ancestral pop\n",
    "#full_model.add_time_param(\"t_bmbo_anc\", lower = 10000, upper = 2000000, t0 = 1500000, upper_constraints = [\"t_mm_crm\"])\n",
    "full_model.add_time_param(\"t_crm_caroli\", lower = 1000, upper = 1000000, upper_constraints = [\"t_mm_crm\"])\n",
    "full_model.add_time_param(\"t_mongo_caroli\", lower = 100, upper = 500000, upper_constraints = [\"t_crm_caroli\"])\n",
    "full_model.add_time_param(\"t_mongo_pungu\", lower = 100, upper = 500000, upper_constraints = [\"t_mongo_caroli\"])\n",
    "full_model.add_time_param(\"t_pungu_dikume\", lower = 100, upper = 500000, upper_constraints = [\"t_mongo_pungu\"])\n",
    "\n",
    "# Start adding leaves to the model\n",
    "# And set pop sizes, for a time-range constrained by divergence\n",
    "full_model.add_leaf(\"SgalMM\", N=\"n_mm_3\", t=0)\n",
    "full_model.set_size(\"SgalMM\", N=\"n_mm\", t=2000000)\n",
    "full_model.set_size(\"SgalMM\", N=\"n_mm\", t=\"t_mm_crm\")\n",
    "full_model.set_size(\"SgalMM\", N=\"n_mm_1\", t=lambda params: params.t_mm_crm * 0.5)\n",
    "full_model.set_size(\"SgalMM\", N=\"n_mm_2\", t=lambda params: params.t_mm_crm * 0.1)\n",
    "full_model.set_size(\"SgalMM\", N=\"n_mm_3\", t=lambda params: params.t_mm_crm * 0.05)\n",
    "\n",
    "full_model.add_leaf(\"SgalCRM\", N=\"n_crm_3\", t=0)\n",
    "full_model.set_size(\"SgalCRM\", N=\"n_crm\", t=\"t_mm_crm\")\n",
    "full_model.set_size(\"SgalCRM\", N=\"n_crm_1\", t=\"t_crm_caroli\")\n",
    "full_model.set_size(\"SgalCRM\", N=\"n_crm_1\", t=lambda params: params.t_crm_caroli * 0.5)\n",
    "full_model.set_size(\"SgalCRM\", N=\"n_crm_2\", t=lambda params: params.t_crm_caroli * 0.1)\n",
    "full_model.set_size(\"SgalCRM\", N=\"n_crm_3\", t=lambda params: params.t_crm_caroli * 0.05)\n",
    "\n",
    "full_model.add_leaf(\"caroli\", N=\"n_caroli_3\", t=0)\n",
    "full_model.set_size(\"caroli\", N=\"n_caroli\", t=\"t_crm_caroli\")\n",
    "full_model.set_size(\"caroli\", N=\"n_caroli\", t=\"t_mongo_caroli\")\n",
    "full_model.set_size(\"caroli\", N=\"n_caroli_1\", t=lambda params: params.t_crm_caroli * 0.5)\n",
    "full_model.set_size(\"caroli\", N=\"n_caroli_2\", t=lambda params: params.t_crm_caroli * 0.1)\n",
    "full_model.set_size(\"caroli\", N=\"n_caroli_3\", t=lambda params: params.t_crm_caroli * 0.05)\n",
    "\n",
    "full_model.add_leaf(\"mongo\", N=\"n_mongo_3\", t=0)\n",
    "full_model.set_size(\"mongo\", N=\"n_mongo\", t=\"t_mongo_caroli\")\n",
    "full_model.set_size(\"mongo\", N=\"n_mongo\", t=\"t_mongo_pungu\")\n",
    "full_model.set_size(\"mongo\", N=\"n_mongo_1\", t=lambda params: params.t_mongo_pungu * 0.5)\n",
    "full_model.set_size(\"mongo\", N=\"n_mongo_2\", t=lambda params: params.t_mongo_pungu * 0.1)\n",
    "full_model.set_size(\"mongo\", N=\"n_mongo_3\", t=lambda params: params.t_mongo_pungu * 0.05)\n",
    "\n",
    "full_model.add_leaf(\"pungu\", N=\"n_pungu_3\", t=0)\n",
    "full_model.set_size(\"pungu\", N=\"n_pungu\", t=\"t_mongo_pungu\")\n",
    "full_model.set_size(\"pungu\", N=\"n_pungu\", t=\"t_pungu_dikume\")\n",
    "full_model.set_size(\"pungu\", N=\"n_pungu_1\", t=lambda params: params.t_pungu_dikume * 0.5)\n",
    "full_model.set_size(\"pungu\", N=\"n_pungu_2\", t=lambda params: params.t_pungu_dikume * 0.1)\n",
    "full_model.set_size(\"pungu\", N=\"n_pungu_3\", t=lambda params: params.t_pungu_dikume * 0.05)\n",
    "\n",
    "full_model.add_leaf(\"dikume\", N=\"n_dikume_2\", t=0)\n",
    "full_model.set_size(\"dikume\", N=\"n_dikume\", t=\"t_pungu_dikume\")\n",
    "full_model.set_size(\"dikume\", N=\"n_dikume\", t=lambda params: params.t_pungu_dikume * 0.5)\n",
    "full_model.set_size(\"dikume\", N=\"n_dikume_1\", t=lambda params: params.t_pungu_dikume * 0.1)\n",
    "full_model.set_size(\"dikume\", N=\"n_dikume_2\", t=lambda params: params.t_pungu_dikume * 0.05)\n",
    "\n",
    "\n",
    "# And now divergences, with free time and assuming pop size is inherited \n",
    "full_model.move_lineages(\"SgalCRM\", \"SgalMM\", t=\"t_mm_crm\", N=\"n_crm\")\n",
    "full_model.move_lineages(\"caroli\", \"SgalCRM\", t=\"t_crm_caroli\", N=\"n_caroli\")\n",
    "full_model.move_lineages(\"mongo\", \"caroli\", t=\"t_mongo_caroli\", N=\"n_mongo\")\n",
    "full_model.move_lineages(\"pungu\", \"mongo\", t=\"t_mongo_pungu\", N=\"n_pungu\")\n",
    "full_model.move_lineages(\"dikume\", \"pungu\", t=\"t_pungu_dikume\", N=\"n_dikume\")\n",
    "\n",
    "# F-statistics indicate some evidentce of hybridization. \n",
    "# So, let's include these in the model.\n",
    "# Specifically, let's include:\n",
    "# 1) a 5% pulse of migration from mongo to dikume\n",
    "# 2) a 4% pulse of migration from mongo to pungu\n",
    "# 3) a 7% pulse of migration from kidume to Sgal CRM\n",
    "# 4) a 12% pulse of migration from mongo to Sgal CRM\n",
    "# But let's set as free parameters, with magnitude bounded by reasonable priors. \n",
    "# first the pulse (between which Spp and what magnitude)\n",
    "# For now, let's just model the instances of hybridization from riverine into bmbo\n",
    "full_model.add_pulse_param(\"p_dikume_mongo\", p0 = 0.05, upper = 0.5)\n",
    "full_model.add_pulse_param(\"p_pungu_mongo\", p0 = 0.04, upper = 0.5)\n",
    "full_model.add_pulse_param(\"p_caroli_mongo\", p0 = 0.03, upper = 0.5)\n",
    "full_model.add_pulse_param(\"p_SgalCRM_dikume\", p0 = 0.07, upper = 0.5)\n",
    "full_model.add_pulse_param(\"p_SgalCRM_mongo\", p0 = 0.12, upper = 0.5)\n",
    "full_model.add_pulse_param(\"p_SgalCRM_caroli\", p0 = 0.12, upper = 0.5)\n",
    "\n",
    "# and then the time\n",
    "full_model.add_time_param(\"t_p_dikume_mongo\", upper_constraints=[\"t_pungu_dikume\"])\n",
    "full_model.add_time_param(\"t_p_pungu_mongo\", upper_constraints=[\"t_mongo_pungu\"])\n",
    "full_model.add_time_param(\"t_p_caroli_mongo\", upper_constraints=[\"t_mongo_caroli\"])\n",
    "full_model.add_time_param(\"t_p_SgalCRM_dikume\", upper_constraints=[\"t_pungu_dikume\"])\n",
    "full_model.add_time_param(\"t_p_SgalCRM_mongo\", upper_constraints=[\"t_mongo_caroli\"])\n",
    "full_model.add_time_param(\"t_p_SgalCRM_caroli\", upper_constraints=[\"t_mongo_caroli\"])\n",
    "\n",
    "\n",
    "full_model.move_lineages(\"mongo\", \"dikume\", t=\"t_p_dikume_mongo\", p=\"p_dikume_mongo\")\n",
    "full_model.move_lineages(\"pungu\", \"mongo\", t=\"t_p_pungu_mongo\", p=\"p_pungu_mongo\")\n",
    "full_model.move_lineages(\"caroli\", \"mongo\", t=\"t_p_caroli_mongo\", p=\"p_caroli_mongo\")\n",
    "full_model.move_lineages(\"dikume\", \"SgalCRM\", t=\"t_p_SgalCRM_dikume\", p=\"p_SgalCRM_dikume\")\n",
    "full_model.move_lineages(\"mongo\", \"SgalCRM\", t=\"t_p_SgalCRM_mongo\", p=\"p_SgalCRM_mongo\")\n",
    "full_model.move_lineages(\"caroli\", \"SgalCRM\", t=\"t_p_SgalCRM_caroli\", p=\"p_SgalCRM_caroli\")\n",
    "\n",
    "\n",
    "# Now plot to see if this is coherent\n",
    "\n",
    "yticks = [500,10000,25000,50000,100000,250000,500000,1000000]\n",
    "# linthreshy will set to the divergence time between caroli and mongo - we pull out this value below:\n",
    "thresh = list(dict(full_model.get_params()).values())[24]\n",
    "\n",
    "fig = momi.DemographyPlot(\n",
    "    full_model, [\"dikume\", \"pungu\", \"mongo\", \"caroli\", \"SgalCRM\", \"SgalMM\"],\n",
    "    figsize=(10,12), linthreshy=thresh, \n",
    "    major_yticks=yticks)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.savefig(\"./AllAdmix-PreFit.png\")\n",
    "plt.savefig(\"./AllAdmix-PreFit.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, it seems like including all samples in this admixture model is just too much for momi to handle\n",
    "# - it runs out fo memory. \n",
    "# As a trial, see if we can reduce the problem by downsampling allele counts to 5 inds per pop\n",
    "\n",
    "# The next few cells only need to be run once.\n",
    "\n",
    "# First read in the allele count data\n",
    "ac = momi.SnpAlleleCounts.load(\"/global/scratch/users/austinhpatton/cichlids/cameroon/Onil_UMD/momi/data/BM-momi-FinalSamps.snpAlleleCounts.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then downsample, and save\n",
    "pop_dict = {\n",
    "    \"dikume\" : 5,\n",
    "    \"pungu\" : 5,\n",
    "    \"mongo\" : 5,\n",
    "    \"caroli\" : 5,\n",
    "    \"SgalCRM\" : 5,\n",
    "    \"SgalMM\": 5\n",
    "}\n",
    "\n",
    "downsamp_ac = ac.down_sample(pop_dict)\n",
    "downsamp_ac.dump(\"/global/scratch/users/austinhpatton/cichlids/cameroon/Onil_UMD/momi/data/BM-momi-FinalSamps-Downsamp5.snpAlleleCounts.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, recalculate the site frequency spectrum from these downsampled allele counts. \n",
    "downsamp_sfs = downsamp_ac.extract_sfs(100)\n",
    "\n",
    "# And save\n",
    "downsamp_sfs.dump(\"/global/scratch/users/austinhpatton/cichlids/cameroon/Onil_UMD/momi/data/BM-momi-FinalSamps-Downsamp5.sfs.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great, so that seems to be what we want.\n",
    "# Now, let's read in the SFS obtained outside of this script. \n",
    "sfs = momi.Sfs.load(\"/global/scratch/users/austinhpatton/cichlids/cameroon/Onil_UMD/momi/data/BM-momi-FinalSamps-Downsamp5.sfs.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this as the data to be used by the model\n",
    "full_model.set_data(sfs, mem_chunk_size=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And go ahead and infer!\n",
    "# Because of the size of the model, we're going to do some exploration of parameter space\n",
    "# We will loop through several times, doing a few rounds of stochastic optimization, \n",
    "# and then we will continue this from the best starting point\n",
    "results = []\n",
    "n_runs = 10\n",
    "for i in range(n_runs):\n",
    "    print(f\"Starting run {i+1} out of {n_runs}...\")\n",
    "    \n",
    "     #Copy the model, randomizing the parameter values\n",
    "    full_rand_model = full_model.copy()\n",
    "    full_rand_model.set_params(\n",
    "        randomize=True)\n",
    "    \n",
    "    checks = \"AllAdmix-RandStart-StochOptim-Checkpoints-InitFit.txt\"\n",
    "    results.append(full_rand_model.stochastic_optimize(snps_per_minibatch=1000, \n",
    "                                                       printfreq=100,\n",
    "                                                       num_iters=500, \n",
    "                                                       svrg_epoch=100,\n",
    "                                                       save_to_checkpoint = checks))\n",
    "    dill.dump_session('AllAdmix-StochOptim-tmp_dill.pkl')\n",
    "    \n",
    "\n",
    "\n",
    "# sort results according to log likelihood, pick the best (largest) one\n",
    "best_result = sorted(results, key=lambda r: r.log_likelihood)[-1]\n",
    "\n",
    "full_model.set_params(best_result.parameters)\n",
    "\n",
    "# Okay, that was a lot of work. Now, save the workspace to an intermediate. \n",
    "dill.dump_session('AllAdmix-RandStarts_dill_InitFit.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot it!\n",
    "\n",
    "# linthreshy will set to the divergence time between caroli and mongo - we pull out this value below:\n",
    "thresh = list(dict(full_model.get_params()).values())[24]\n",
    "\n",
    "fig = momi.DemographyPlot(\n",
    "    full_model, [\"dikume\", \"pungu\", \"mongo\", \"caroli\", \"SgalCRM\", \"SgalMM\"],\n",
    "    figsize=(10,12),\n",
    "    major_yticks=yticks,\n",
    "    linthreshy=thresh)\n",
    "\n",
    "plt.savefig(\"AllAdmix-RandStarts-StochastOptim-Fitted.png\")\n",
    "plt.savefig(\"AllAdmix-RandStarts-StochastOptim-Fitted.pdf\")\n",
    "\n",
    "full_model.get_params()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# This fitting procedure (including the earlier stochastic optimizization) takes which a long time. \n",
    "# Ended up hitting the 72 hour time limit on the bigmem savio nodes (also quite memory intensive),\n",
    "# so we're going to update the parameters of the full model here to be the same as what was reached\n",
    "# in the last iteration of the L-BFGS-B optimization procedure before the job was cancelled. \n",
    "# Last step: INFO:momi.demo_model:{it: 208, KLDivergence: Autograd ArrayBox with value 0.0908904874112342}\n",
    "\n",
    "dill.load_session('AllAdmix-RandStarts_dill_InitFit.pkl')\n",
    "\n",
    "newest_params = {'n_mm': 49999999.99999999, 'n_crm': 126906.62813382912, \n",
    "                 'n_mongo': 15760.384948624753, 'n_pungu': 90049.20151010553, \n",
    "                 'n_dikume': 26907.48641417023, 'n_caroli': 33281.10328474059, \n",
    "                 'n_mm_1': 517260.3009338876, 'n_crm_1': 5729470.402328302, \n",
    "                 'n_mongo_1': 134743.47637289506, 'n_pungu_1': 106290.26766388012, \n",
    "                 'n_dikume_1': 2606.092988805131, 'n_caroli_1': 273.57350258168077, \n",
    "                 'n_mm_2': 18753.540161922345, 'n_crm_2': 995800.1672198448, \n",
    "                 'n_caroli_2': 252561.5357660461, 'n_mongo_2': 83418.58307945068, \n",
    "                 'n_pungu_2': 1316.5796224710584, 'n_dikume_2': 14564.644991469302, \n",
    "                 'n_mm_3': 49999999.99999999, 'n_crm_3': 11359.467327588545, \n",
    "                 'n_caroli_3': 137722.9948566717, 'n_mongo_3': 568.9146821018952, \n",
    "                 'n_pungu_3': 27368.18687032608, 't_mm_crm': 280645.3195825911, \n",
    "                 't_crm_caroli': 87617.63823326302, 't_mongo_caroli': 44094.57796405377, \n",
    "                 't_mongo_pungu': 20621.129004557275, 't_pungu_dikume': 15790.53300240068, \n",
    "                 'p_dikume_mongo': 0.14150837101350486, 'p_pungu_mongo': 0.17991833540889018, \n",
    "                 'p_caroli_mongo': 0.03352510290085085, 'p_SgalCRM_dikume': 0.0040362924721478784, \n",
    "                 'p_SgalCRM_mongo': 0.05088657962989328, 'p_SgalCRM_caroli': 0.029539104631394753, \n",
    "                 't_p_dikume_mongo': 15622.390313997917, 't_p_pungu_mongo': 2415.8507430564878, \n",
    "                 't_p_caroli_mongo': 42482.39212759363, 't_p_SgalCRM_dikume': 15681.610358939119, \n",
    "                 't_p_SgalCRM_mongo': 23073.959129754574, 't_p_SgalCRM_caroli': 35866.74974733347}\n",
    "\n",
    "full_model.set_params(newest_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now do a full optimization of the model from this starting point.\n",
    "full_model.optimize(method=\"L-BFGS-B\")\n",
    "\n",
    "# And again, we really want to make sure we save this for later bootstrapping\n",
    "# Importantly, we need to save these intermediate models - let's try doing so using the pickle module\n",
    "dill.dump_session('AllAdmix-RandStarts_dill_InitFit.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the session\n",
    "dill.load_session('AllAdmix-RandStarts_dill_InitFit.pkl')\n",
    "\n",
    "# Plot the fully optimized model!\n",
    "# linthreshy will set to the divergence time between caroli and mongo - we pull out this value below:\n",
    "thresh = list(dict(full_model.get_params()).values())[24]\n",
    "\n",
    "fig = momi.DemographyPlot(\n",
    "    full_model, [\"dikume\", \"pungu\", \"mongo\", \"caroli\", \"SgalCRM\", \"SgalMM\"],\n",
    "    figsize=(10,12),\n",
    "    major_yticks=yticks,\n",
    "    linthreshy=thresh)\n",
    "\n",
    "plt.savefig(\"AllAdmix-RandStarts_L-BFGS-B-Fitted.png\")\n",
    "plt.savefig(\"AllAdmix-RandStarts_L-BFGS-B-Fitted.pdf\")\n",
    "\n",
    "ests = dict(full_model.get_params())\n",
    "\n",
    "with open('AllAdmix-RandStarts_L-BFGS-B_FittedParams.txt', \"w\") as f:\n",
    "    grp = \"Observed\"\n",
    "    print(\"Set\", \"Parameter\", \"Estimate\", file=f)\n",
    "    for parameter, estimate in ests.items():\n",
    "        print(grp, '{} {}'.format(parameter, estimate), file=f)\n",
    "\n",
    "full_model.log_likelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets assess the extent to which the fitted model adequately explains our observed data\n",
    "full_model_stats = momi.SfsModelFitStats(full_model)\n",
    "\n",
    "# Using the f4 statistics\n",
    "print(\"Computing f4(dikume, pungu, mongo, SgalCRM)\")\n",
    "f4 = full_model_stats.f4(\"dikume\", \"pungu\", \"mongo\", \"SgalCRM\")\n",
    "\n",
    "print(\"Expected = {}\".format(f4.expected))\n",
    "print(\"Observed = {}\".format(f4.observed))\n",
    "print(\"SD = {}\".format(f4.sd))\n",
    "print(\"Z(Expected-Observed) = {}\".format(f4.z_score))\n",
    "\n",
    "# an alternative including all pops that CRM supposedly has hybridized with\n",
    "print(\"Computing f4(dikume, mongo, caroli, SgalCRM)\")\n",
    "f4 = full_model_stats.f4(\"dikume\", \"mongo\", \"caroli\", \"SgalCRM\")\n",
    "\n",
    "print(\"Expected = {}\".format(f4.expected))\n",
    "print(\"Observed = {}\".format(f4.observed))\n",
    "print(\"SD = {}\".format(f4.sd))\n",
    "print(\"Z(Expected-Observed) = {}\".format(f4.z_score))\n",
    "\n",
    "# Only within lake\n",
    "print(\"Computing f4(dikume, pungu, mongo, caroli)\")\n",
    "f4 = full_model_stats.f4(\"dikume\", \"pungu\", \"mongo\", \"caroli\")\n",
    "\n",
    "print(\"Expected = {}\".format(f4.expected))\n",
    "print(\"Observed = {}\".format(f4.observed))\n",
    "print(\"SD = {}\".format(f4.sd))\n",
    "print(\"Z(Expected-Observed) = {}\".format(f4.z_score))\n",
    "\n",
    "# Pairwise IBS\n",
    "full_model_stats.all_pairs_ibs()\n",
    "\n",
    "# And again, save the session, to a new pickle file in case anything gets messed up and overwritten\n",
    "dill.dump_session('AllAdmix-RandStarts-Final-Fitted_dill.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of curiosity, let's see what the per-generation mutation rate is estimated as per population?\n",
    "full_model.fit_within_pop_diversity()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momi",
   "language": "python",
   "name": "momi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
